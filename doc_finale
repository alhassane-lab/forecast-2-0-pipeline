# Documentation Finale - Forecast 2.0 Pipeline

## 1. Objectif du projet

Forecast 2.0 Pipeline est une chaîne Data Engineering qui couvre de bout en bout :
- l'extraction de données météo multi-sources (InfoClimat, Weather Underground),
- le stockage de données brutes et transformées sur S3,
- l'harmonisation vers un schéma unifié MongoDB,
- la validation qualité et le calcul de métriques de complétude,
- le chargement vers MongoDB (local ou ECS),
- l'observabilité (logs, rapports, métriques EMF, alarmes CloudWatch),
- l'exploitation production (conteneurs, Terraform, backups, monitoring).

Le projet est orienté production avec exécution locale Docker et déploiement AWS ECS.

## 2. Architecture globale

### 2.1 Flux logique

`Airbyte/Raw -> S3 Raw -> Extract -> Harmonize -> Validate -> Save Processed S3 -> Load MongoDB -> Reports + Metrics`

### 2.2 Composants principaux

- Sources : exports Airbyte en JSON/JSONL (InfoClimat et Weather Underground).
- Stockage brut : bucket S3 raw (`S3_RAW_BUCKET`).
- ETL Python : orchestré par `src/main.py`.
- Stockage transformé : bucket S3 processed (`S3_PROCESSED_BUCKET`, préfixe `processed/`).
- Stockage cible : MongoDB (`weather_measurements` dans `forecast_2_0`).
- Observabilité app : logs `loguru`, rapports JSON, métriques EMF.
- Observabilité infra : CloudWatch Logs/Alarms + SNS.
- Infra AWS : ECS Fargate, Cloud Map, EBS managé, Secrets Manager, VPC endpoints, AWS Backup.

## 3. Stack technique

### 3.1 Langage et packaging

- Python `^3.10` (runtime Docker en `3.11-slim`).
- Poetry (`pyproject.toml`) avec scripts CLI.

### 3.2 Librairies métier clés

- `boto3`, `botocore` : accès S3 et services AWS.
- `pymongo`, `dnspython`, `certifi` : connexion et opérations MongoDB.
- `pydantic`, `jsonschema` : validation/config.
- `loguru`, `python-json-logger` : logs structurés.
- `tenacity` : base de retry côté utilitaires.

### 3.3 Dev/Test/Qualité

- `pytest`, `pytest-cov`, `pytest-mock`, `pytest-asyncio`.
- `black`, `flake8`, `mypy`, `isort`, `pylint`.

## 4. Structure du dépôt

- `src/main.py` : orchestrateur du pipeline complet.
- `src/pipeline/extractors/` : extracteurs InfoClimat / Weather Underground.
- `src/pipeline/transformers/` : harmonisation, validation, qualité.
- `src/loaders/` : chargement MongoDB et S3 processed.
- `src/scripts/` : scripts unitaires (transform, migrate, CRUD, latence).
- `src/config/` : configuration pipeline, schéma MongoDB, métadonnées stations.
- `infra/terraform/mongodb-ecs/` : stack MongoDB ECS + monitoring + backup.
- `ops/` : scripts d'exploitation (cron, build image, deploy Terraform, création user app).
- `docker/` : artefacts conteneur MongoDB RS et init local.
- `docs/` : audits, guides migration et déploiement.

## 5. Pipeline applicatif détaillé

## 5.1 Orchestration (`src/main.py`)

Le pipeline exécute les étapes suivantes dans l'ordre :

1. `extract_data()`
- Lit InfoClimat et Weather Underground via S3 (ou fallback date récente disponible).
- Alimente les compteurs `records_extracted`.

2. `transform_data()`
- Convertit chaque record source vers un format unifié MongoDB (`DataHarmonizer`).
- Comptabilise les rejets d'harmonisation.

3. `validate_data()`
- Applique les règles métier (`DataValidator`).
- Sépare valide/rejeté, enrichit `data_quality`.

4. `save_validated_to_s3()`
- Persiste le lot validé dans `s3://<processed-bucket>/processed/weather_data_YYYYMMDD_HHMMSS.json`.

5. `load_data()`
- Charge MongoDB via `MongoDBLoader.bulk_insert()`.
- En mode `--dry-run`, simule sans écrire.

6. `generate_quality_report()`
- Produit `logs/quality_report_*.json`.

7. Finalisation
- Écrit `logs/pipeline_status.json`.
- Émet métriques EMF via `emit_pipeline_metrics()`.

## 5.2 Gestion de la date

- Si `--date` absent, la date cible est J-1 UTC.
- Les extracteurs essaient le dernier fichier de la date puis fallback dernier fichier disponible.

## 5.3 Gestion des erreurs

- Les erreurs par source sont collectées dans `stats["errors"]`.
- En cas d'exception globale : statut `FAILED`, métriques tout de même émises.
- Code de sortie CLI : `0` sans erreurs, `1` sinon.

## 6. Extraction des données

## 6.1 InfoClimat (`src/pipeline/extractors/infoclimat_extractor.py`)

- Lit des `.jsonl` depuis `airbyte-sync/infoclimat/data_infoclimat/`.
- Parse `_airbyte_data.hourly` par station.
- Utilise `stations_metadata.json` pour enrichir localisation/station.
- Nettoie timestamps et structure les mesures brutes.

## 6.2 Weather Underground (`src/pipeline/extractors/wunderground_extractor.py`)

- Lit le dernier `.jsonl` par station dans `airbyte-sync/wunderground/<folder>/`.
- Parse `_airbyte_data` et convertit les champs numériques.
- Enrichit avec métadonnées station (matériel, software, géographie).

## 7. Harmonisation et validation

## 7.1 Harmonisation (`src/pipeline/transformers/data_harmonizer.py`)

- Produit un document cible avec blocs :
  - `station`,
  - `timestamp`,
  - `measurements` (structure `{ value, unit }`),
  - `data_quality`,
  - `metadata`.
- Normalise la direction du vent WU (cardinal -> degrés).
- Gère plusieurs formats timestamp (ISO, formats US AM/PM).
- Crée `station.location_geo` GeoJSON pour index 2dsphere.

## 7.2 Validation (`src/pipeline/transformers/data_validator.py`)

- Vérifie champs obligatoires (station, timestamp, localisation).
- Valide plages de mesures (température, humidité, pression, etc.).
- Vérifie cohérences métier :
  - `dewpoint <= temperature`,
  - `wind_gust >= wind_speed`.
- Calcule `completeness_score` et liste des champs manquants.
- Mode strict optionnel (`validation.strict_mode`).

## 7.3 Qualité (`src/pipeline/transformers/quality_checker.py`)

Génère un rapport agrégé avec :
- résumé exécution et taux de rejet,
- stats par station et réseau,
- complétude par champ,
- couverture temporelle,
- distribution des scores qualité,
- anomalies détectées (limitée à 100).

## 8. Chargement et modèle MongoDB

## 8.1 Loader MongoDB (`src/loaders/mongodb_loader.py`)

- Lit la connexion depuis `MONGODB_URI` (obligatoire hors dry-run).
- Supporte TLS configurable via env (`MONGODB_TLS`, `MONGODB_TLS_ALLOW_INVALID_CERTS`).
- Crée les index :
  - unique : `station.id + timestamp`,
  - recherche : `station.network + timestamp`,
  - géospatial : `station.location_geo` (`2dsphere`).
- Supprime les doublons existants avant création index unique.
- Modes : `insert_many` et `upsert`.

## 8.2 Schéma cible (`src/config/mongodb_schema.json`)

Collection principale : `weather_measurements`.

Structure métier :
- `station` (id, réseau, localisation, matériel éventuel),
- `timestamp`,
- `measurements`,
- `data_quality`,
- `metadata`.

## 9. CLI et scripts d'exploitation applicative

## 9.1 Entrée principale

- `poetry run forecast-pipeline --date YYYY-MM-DD --log-level INFO [--dry-run]`

## 9.2 Scripts spécialisés

- Transformation only :
  - `poetry run transform-mongodb --source-mode s3 --date 2026-02-18`
  - `poetry run transform-mongodb --source-mode local --infoclimat-file ... --wunderground-file ...`

- Migration Mongo :
  - `poetry run migrate-mongodb --input data/processed/mongodb_ready_records.json`
  - `poetry run migrate-mongodb --input-s3-date 2026-02-18`
  - `poetry run migrate-mongodb --upsert`

- CRUD smoke :
  - `poetry run mongodb-crud`

- Latence requêtes :
  - `poetry run latency-report --station-id ILAMAD25 --date 2026-02-18 --iterations 10`

## 10. Conteneurisation

## 10.1 Conteneur pipeline (`Dockerfile`)

- Base : `python:3.11-slim`.
- Installe Poetry, dépendances `main`.
- Copie `src/` uniquement.
- EntryPoint : `python -m main`.

## 10.2 Compose principal (`docker-compose.yml`)

Service `pipeline` :
- image build locale,
- injecte env AWS/Mongo,
- monte `./logs` et `${HOME}/.aws` (read-only),
- commande défaut `--log-level INFO`.

## 10.3 Compose local Mongo (`docker-compose.local.yml`)

Ajoute :
- service `mongo` (image `mongo:6`),
- init script `docker/mongo-init/10-create-app-user.js` (create/update user applicatif),
- override `MONGODB_URI` du service `pipeline` vers mongo local.

## 10.4 Makefile

Cibles utiles :
- `make up-ecs`, `make up-local`, `make down-local`, `make logs`, `make test`.
- `make mongo-shell`, `make mongo-shell-root`.

## 11. Infrastructure AWS (Terraform)

Répertoire : `infra/terraform/mongodb-ecs/`.

## 11.1 Composants déployés

- Réseau : subnets privés dédiés Mongo, NAT, route table, VPC endpoints.
- Sécurité : security groups Mongo + endpoints.
- Service discovery : namespace privé Cloud Map + services `mongo-1/2/3`.
- Secrets : secret bootstrap (root password + repl key).
- ECS : cluster + task definitions + services Fargate (3 noeuds).
- Stockage : volumes EBS managés attachés aux services ECS.
- Logs : CloudWatch log group Mongo.

## 11.2 Sauvegardes (AWS Backup)

Déployé et actif :
- `aws_backup_vault.mongodb`
- `aws_backup_plan.mongodb`
- `aws_backup_selection.mongodb_ebs_by_tag`
- IAM role Backup + policies

Configuration par variables :
- `enable_backups`
- `backup_schedule`
- `backup_start_window_minutes`
- `backup_completion_window_minutes`
- `backup_cold_storage_after_days`
- `backup_delete_after_days`

Sorties Terraform associées :
- `backup_vault_name`
- `backup_plan_id`

## 11.3 Monitoring AWS

Déployé et actif :
- SNS topic : `forecast-prod-mongo-alerts`
- Alarmes ECS par service :
  - running task count bas,
  - CPU high,
  - memory high.
- Metric filter logs Mongo (`s=E/F`) + alarme `mongo_error_logs`.

Configuration par variables :
- `enable_monitoring`
- `alarm_notification_emails`
- `ecs_running_task_minimum`
- `ecs_cpu_high_threshold`
- `ecs_memory_high_threshold`
- `mongodb_error_log_alarm_threshold`

Sortie Terraform associée :
- `alarm_topic_arn`

## 11.4 Backend Terraform

- Backend S3 via `backend.tf` + `backend.hcl.example`.
- Script de déploiement : `ops/aws/deploy_mongodb_rs_terraform.sh`.
- Variables backend requises :
  - `TF_BACKEND_BUCKET`
  - `TF_BACKEND_KEY`

## 12. Opérations AWS et runbooks

## 12.1 Build/push image MongoDB RS

- Script : `ops/aws/build_push_mongodb_rs_image.sh`
- Actions : create repo ECR si absent, login ECR, build `docker/mongodb-rs/Dockerfile`, push image.

## 12.2 Déploiement infra MongoDB ECS

- Script : `ops/aws/deploy_mongodb_rs_terraform.sh`
- Exécute : `terraform init` (backend), `plan`, `apply`.

## 12.3 Gestion utilisateur applicatif MongoDB ECS

- Script : `ops/aws/create_mongo_app_user.sh`
- Fonction : create/update user applicatif sur DB cible via `ecs execute-command`.
- Inputs requis : `APP_USER`, `APP_PASS`.

## 12.4 Planification pipeline

- Cron local : `ops/cron-run-pipeline.sh`.
- Environnement AWS : EventBridge (règle externe au repo).

## 13. Observabilité applicative

Fichiers générés dans `logs/` :
- `pipeline_status.json`
- `quality_report_*.json`
- `migration_report_*.json`
- `query_latency_report_*.json`
- logs journaliers `pipeline_YYYY-MM-DD.log`.

Métriques EMF imprimées sur stdout (`utils.monitoring.emit_pipeline_metrics`) :
- `duration_seconds`,
- `records_extracted`, `records_validated`, `records_loaded`, `records_rejected`,
- `error_rate`,
- `run_success`.

Namespace CloudWatch EMF : `Forecast2Pipeline`.

## 14. Sécurité

- Secrets runtime Mongo root/repl key stockés dans AWS Secrets Manager.
- Auth MongoDB activée (`--auth`) et replica key file obligatoire.
- Communications intra-RS sécurisées par keyFile.
- Principle of least privilege partiel appliqué sur rôles ECS.
- TLS Mongo géré côté URI/env (notamment pour connexions externes).
- Variables sensibles non hardcodées dans le code applicatif.

## 15. Tests et qualité logicielle

Tests présents :
- `src/tests/test_transformers.py`
- `src/tests/test_integration.py`
- `src/tests/test_pipeline_local.py`

Commande standard :
- `poetry run pytest -vv src/tests`

## 16. Configuration environnement

Exemple de référence : `env.example`.

Variables critiques :
- AWS : `AWS_REGION`, `AWS_PROFILE`, `S3_RAW_BUCKET`, `S3_PROCESSED_BUCKET`.
- Mongo : `MONGODB_URI`, `MONGODB_DATABASE`, `MONGODB_COLLECTION`.
- Optionnel local : `MONGO_APP_USERNAME`, `MONGO_APP_PASSWORD`, etc.

## 17. Procédures de déploiement

## 17.1 Local (pipeline + mongo local)

1. `cp env.example .env`
2. Adapter `.env`
3. `make up-local`
4. Tester pipeline / scripts
5. `make down-local` pour nettoyage

## 17.2 Pipeline avec Mongo distant (ECS/Atlas)

1. Définir `MONGODB_URI` valide
2. `make up-ecs`
3. Exécuter scripts `poetry run ...` ou `docker compose run --rm pipeline ...`

## 17.3 Infra AWS MongoDB ECS

1. Configurer `infra/terraform/mongodb-ecs/terraform.tfvars`
2. Exporter variables backend Terraform
3. `bash ops/aws/deploy_mongodb_rs_terraform.sh`
4. Valider `terraform output`

## 18. Troubleshooting

## 18.1 `MONGODB_URI non définie`

- Vérifier `.env` et variables injectées dans Docker/CI.

## 18.2 `Server selection timed out`

- Vérifier état replica set (`rs.status()`).
- Vérifier DNS Cloud Map (`mongo-1.mongo.internal`, etc.).
- Vérifier SG/route/subnets.

## 18.3 `command usersInfo requires authentication`

- Utiliser un utilisateur authentifié (root ou app user).
- Vérifier `authSource` correct.

## 18.4 Subscription SNS non reçue

- Vérifier état `PendingConfirmation` via `aws sns list-subscriptions-by-topic`.
- Confirmer le lien email envoyé par AWS SNS.

## 19. Documents complémentaires

- `README.md` : guide principal d'usage.
- `docs/deployment_mongodb_ecs.md` : historique déploiement ECS.
- `docs/audit_complet_2026-02-18.md` et `docs/audit_ecs_only_2026-02-18.md` : audits techniques.
- `docs/airbyte_setup_s3.md` : setup ingestion Airbyte.
- `docs/mongodb_migration.md` : migration MongoDB.

## 20. État actuel (référence opérationnelle)

- MongoDB ECS replica set actif en 3 noeuds.
- Sauvegardes AWS Backup configurées.
- Alarming CloudWatch + SNS configurés.
- Subscription email définie sur `ali75009@gmail.com` (confirmation email requise côté boîte mail).

---

Ce document est la référence consolidée de l'architecture, de l'exploitation et du déploiement du projet Forecast 2.0 Pipeline.
